{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion and Memory\n",
    "### Matthew Chong A16156411\n",
    "### Daneil Byers A15396367\n",
    "### Steve Kuk A15521681\n",
    "### Robert Aispuro A12086294"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IA. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project, we wanted to analyze data on an individual's ability to comprehend and recall information and see if their ability to execute these tasks are influenced by either positive or negative sentiment. We decided to split the data between age groups and divided them into 3 buckets: 18-25, 30-40, 45-55 as well as splitting the data between 3 columns: recalled, imagined and retold.  We focused on specific columns of information from the dataset such as age, draining, distracted similarity, etc, that can potentially influence one’s ability to comprehend and recall information. We took an approach using these variables to simultaneously analyze memory recollection as well as sentiment for individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IB. Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Does Positive and Negative emotion influence memory(or academic performance) when isolated regardless of environment and regardless of gender?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IC. Background & Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past few years, students' academic performance has been largely affected by the pandemic where in-person classes transitioned into online classes. Traditionally, a student's learning and education has always been delivered in person. Now, students are abruptly forced to adapt to a new learning environment where their education is being delivered through a monitor screen. This sudden change either had a positive or negative academic impact, depending on the prefered learning method on the individual. In the research article, *Integrating students' Perspective about Online Learning: A hierarchy of factors* by Montgomery Van Wart, Van Wart and his team found that the most critical factor of online classes is the \"loss of physical interaction\". The loss of physical interaction demanded a higher level of interactivity and instructional sophistication in the virtual aspect. Furthermore, how students personally feel about the sudden shift in learning may have an influence in their ability to comprehend and recall information delivered through their computers. The research article, *Impact of online classes on the satisfaction and performance of students during the pandemic period of COVID-19* by Ram Gopal, looks at this factor. The study evaluated student's thoughts about how they personally felt about online learning. The study found that \"overall students agreed that online teaching was valuable for them\". From this article, it seems that students are satisfied with online learning. In fact, in another article called *The Influence of Virtual Learning Environments in Students' performance* by Paul Alves, Alves found that the more access a student has to VLE (Virtual Learning Environments), the more this leads to an increase of the number of units they register, an increase in the number of units they pass, and a decrease in the \"percentage of students who failed all course units\". Thus, not only are students satisfied with online learning, they are also overall performing better in their academics. From these articles, we have a general idea that a student's emotions (positive or negative) do in fact play a role in their academic performance.\n",
    "\n",
    "From our own group's experience, we have noticed that it has gotten increasingly difficult to direct our attention and retain knowledge given in class. As a result of this, we are motivated in finding the factors that influence attention. We want to uncover if positive,negative or neutral emotions contribute to one's ability to focus, retain memory and perform cognitive tasks. More in-depth, we are interested in measuring the difference of cognitive performance when one's emotion is changed. As a result we believe that it is crucial to find the most productive way to retain academic knowledge so that we can better assist fellow students during these unusual times.\n",
    "\n",
    "- https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-020-00229-8\n",
    "- https://link.springer.com/article/10.1007/s10639-021-10523-1\n",
    "- https://www.semanticscholar.org/paper/The-Influence-of-Virtual-Learning-Environments-in-Alves-Miranda/a7c7ba6194633bd68a300522089c795fb4c83a79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID. Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an individual is infected with positive emotion then their ability to comprehend and recall information is enhanced. Likewise, if an individual is infected with negative emotions then their ability to comprehend information is imperiled. Positive emotion is supplemental to learning and memory recollection because we believe positive sentiment influences motivation as well as focus which are two essential factors in memory. Negative emotion is detrimental to learning and memory recollection because having a negative mindset in the context of a learning environment restricts one's ability to recall and comprehend new information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IIA. Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import all the packages and data we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installations required\n",
    "\n",
    "#python -m spacy download en_core_web_lg\n",
    "#pip install spacy\n",
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vaderSentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_312/4279247337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvaderSentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaderSentiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vaderSentiment'"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "from lisc import Counts\n",
    "from lisc.utils.db import SCDB\n",
    "from lisc.plts.counts import *\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import spacy\n",
    "\n",
    "#Data Import\n",
    "hippDf = pd.read_csv('hippoCorpusV2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IIB. Data Wrangling and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we will do some data wrangling and cleaning. We are going to focus on these columns and check for null values:\n",
    "- annotatorAge: Lower limit of the age bucket of the worker.\n",
    "  Buckets are: 18-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54,55+\n",
    "  \n",
    "- story: Story about the imagined or recalled event (15-25     sentences)\n",
    "- distracted: How distracted were you while writing your story? (5-point Likert)\n",
    "\n",
    "- draining: How taxing/draining was writing for you emotionally? (5-point Likert)\n",
    "\n",
    "- frequency: How often do you think about or talk about this event? (5-point Likert)\n",
    "\n",
    "- importance: How impactful, important, or personal is this story/event to you? (5-point Likert)\n",
    "\n",
    "- logTimeSinceEvent: Log of time (days) since the recalled event happened\n",
    "\n",
    "- mainEvent: Short phrase describing the main event described\n",
    "\n",
    "- similarity: How similar to your life does this event/story feel to you? (5-point Likert)\n",
    "\n",
    "- stressful: How stressful was this writing task? (5-point Likert)\n",
    "\n",
    "- summary: Summary of the events in the story (1-3 sentences)\n",
    "\n",
    "- timeSinceEvent: Time (number of days) since the recalled event happened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for null values\n",
    "Let's check to see if our dataset has any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values, if null value found returns True\n",
    "print('AnnotatorAge null values ... ',hippDf['annotatorAge'].isnull().values.any())\n",
    "print('Story null values ...        ',hippDf['story'].isnull().values.any())\n",
    "print('Distracted null values ...   ', hippDf['distracted'].isnull().values.any())\n",
    "print('Draining null values ...     ', hippDf['draining'].isnull().values.any())\n",
    "print('Frequency null values ...    ', hippDf['frequency'].isnull().values.any())\n",
    "print('Importance null values ...   ', hippDf['importance'].isnull().values.any())\n",
    "print('LTSinceEvent null values ... ', hippDf['logTimeSinceEvent'].isnull().values.any())\n",
    "print('Similarity null values ...   ', hippDf['similarity'].isnull().values.any())\n",
    "print('Stressful null values ...    ', hippDf['stressful'].isnull().values.any())\n",
    "print('TimeSinceEvent null values ..', hippDf['timeSinceEvent'].isnull().values.any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are some null values which is expected based on the dataset the was provided. Since we are interested in the age of the indivduals and their emotion we are going to drop any row with a NaN value in the AnnotatorAge column and importance column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNaNHippDf = hippDf.dropna(subset=['annotatorAge','importance',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNaNHippDf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure our dataset is cleaned so there are no more NaN values. Next, let's take a look at the annotatorAge column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNaNHippDf['annotatorAge'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From this, we can see that there are 8 unique age variables. For this project, we will classify the age bucket 18 and 25 as **'Youth'**, 30,35,40 as **'Adults'**, and 45,50,55 as **'Seniors'** into a new column called **\"AgeGroup\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorizes annotatorAge into different age groups\n",
    "def ageGroup(row):\n",
    "    if row['annotatorAge'] == 18 or row['annotatorAge'] == 25:\n",
    "        return 'Youth'\n",
    "    elif row['annotatorAge'] == 30 or row['annotatorAge'] == 35 or row['annotatorAge'] == 40:\n",
    "        return 'Adult'\n",
    "    elif row['annotatorAge'] == 45 or row['annotatorAge'] == 50 or row['annotatorAge'] == 55:\n",
    "        return 'Senior'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply new column\n",
    "ageKey = noNaNHippDf.apply(lambda row: ageGroup(row),axis=1)\n",
    "ageKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNaNHippDf['AgeGroup'] = ageKey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to see if function worked and age was classified into 3 groups\n",
    "noNaNHippDf['AgeGroup'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new column is now set with our unique variables and we can move on to continue wrangling the rest of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data by group\n",
    "Next, we will split the data into 3 groups with the memType column with **\"recalled\"**,**\"imagined\"**, and **\"retold\"** so we can analyze them separately later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalled_df = noNaNHippDf[noNaNHippDf['memType']==\"recalled\"]\n",
    "imagined_df = noNaNHippDf[noNaNHippDf['memType']==\"imagined\"]\n",
    "retold_df = noNaNHippDf[noNaNHippDf['memType']==\"retold\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to focus on these columns:\n",
    "- annotatorAge: Lower limit of the age bucket of the worker.\n",
    "  Buckets are: 18-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54,55+\n",
    "  \n",
    "- story: Story about the imagined or recalled event (15-25     sentences)\n",
    "- distracted: How distracted were you while writing your story? (5-point Likert)\n",
    "\n",
    "- draining: How taxing/draining was writing for you emotionally? (5-point Likert)\n",
    "\n",
    "- frequency: How often do you think about or talk about this event? (5-point Likert)\n",
    "\n",
    "- importance: How impactful, important, or personal is this story/event to you? (5-point Likert)\n",
    "\n",
    "- logTimeSinceEvent: Log of time (days) since the recalled event happened\n",
    "\n",
    "- mainEvent: Short phrase describing the main event described\n",
    "\n",
    "- similarity: How similar to your life does this event/story feel to you? (5-point Likert)\n",
    "\n",
    "- stressful: How stressful was this writing task? (5-point Likert)\n",
    "\n",
    "- summary: Summary of the events in the story (1-3 sentences)\n",
    "\n",
    "- timeSinceEvent: Time (number of days) since the recalled event happened\n",
    "\n",
    "- recAgnPairId: ID of the recalled story that corresponds to this retold story (null for imagined stories). Group on   this variable to get the recalled-retold pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRecalled = recalled_df[['annotatorAge','story','distracted','draining','frequency',\n",
    "                                         'importance','logTimeSinceEvent','mainEvent','similarity',\n",
    "                                         'stressful','summary','timeSinceEvent','AgeGroup','recAgnPairId','memType']]\n",
    "newImagined = imagined_df[['annotatorAge','story','distracted','draining','frequency',\n",
    "                                         'importance','logTimeSinceEvent','mainEvent','similarity',\n",
    "                                         'stressful','summary','timeSinceEvent','AgeGroup','recAgnPairId','memType']]\n",
    "newRetold = retold_df[['annotatorAge','story','distracted','draining','frequency',\n",
    "                                         'importance','logTimeSinceEvent','mainEvent','similarity',\n",
    "                                         'stressful','summary','timeSinceEvent','AgeGroup','recAgnPairId','memType']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing text comparison\n",
    "We are going to look at how similar the stories are between recalled and retold using the spacy package for analysis later. Though, first we need to prepare the data through wrangling. As a reminder, the recalled group is recalling a previous story from their life and the retold group is trying to retell the same story they gave previously based on the summary that they created after they told their start in the recalled group. We are going to make a new table that combines the recalled story and the retold story so that we can more easily apply the spacy package to it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to find the unique id's that link the two data sections together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idTags = noNaNHippDf['recAgnPairId'].unique()\n",
    "#Need to remove the null tag\n",
    "indexOfNull = 0\n",
    "newIdTags = np.delete(idTags,indexOfNull)\n",
    "newIdTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the unique tags we need to find the recalled data and merge it with the retold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfLists = []\n",
    "secondKeyStory = []\n",
    "deltaOfTime = []\n",
    "for tagNumber in range(len(newIdTags)):\n",
    "    #Get df of unique tag\n",
    "    tagIds = hippDf[hippDf['recAgnPairId'] == newIdTags[tagNumber]]\n",
    "    #Grab the first one and add it to the list\n",
    "    mainVal = tagIds.iloc[0]\n",
    "    #Take the story of the second\n",
    "    secondStory = tagIds['story'].iloc[1]\n",
    "    #Check that the data works right\n",
    "    timeSinceRe = tagIds['timeSinceEvent'].iloc[1]\n",
    "    \n",
    "    \n",
    "    #Add them to a list to make a DF out of\n",
    "    listOfLists.append(mainVal)\n",
    "    secondKeyStory.append(secondStory)\n",
    "    deltaOfTime.append(timeSinceRe)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalledAndRetold = pd.DataFrame(listOfLists)\n",
    "recalledAndRetold['retold stories'] = secondKeyStory\n",
    "recalledAndRetold['time since recalled'] = deltaOfTime\n",
    "recalledAndRetold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in row 26, the data in the time since recalled column makes no sense. After doing further investigation this error orginates from how the data was recorded. So to avoid skewed results we are going to remove any result that is above 1111111 days. We chose this point from looking at the data and seeing that it jumps from 780 days to \n",
    "1111111 which is a jump from 2.14 years to 3,044 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedRecalledAndRetold = recalledAndRetold[recalledAndRetold['time since recalled'] < 1111111]\n",
    "cleanedRecalledAndRetold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check and make sure that there are no more extraneous data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedRecalledAndRetold['time since recalled'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we no longer have extraneous data points, our data is properly cleaned and wrangled. We are ready to begin our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IIC. Data Analysis and Results\n",
    "- **Sentiment Analysis**\n",
    "- **Spacy Similarity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run our **Setiment Analysis** first.\n",
    "This is the method that will be used to calculate the sentiment score which will allow us to compare whether the sentiments are positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentScore(dataFrame):\n",
    "    s_score = []\n",
    "    s_rating = []\n",
    "    sentiment_obj = SentimentIntensityAnalyzer()\n",
    "    for i in range(len(dataFrame)):\n",
    "        s_score.append(sentiment_obj.polarity_scores(dataFrame.iloc[i,1]))\n",
    "        comp_score = s_score[i]['compound']\n",
    "        if comp_score > 0.05:\n",
    "            s_rating.append(\"Positive\")\n",
    "        elif comp_score <= -0.05:\n",
    "            s_rating.append(\"Negative\")\n",
    "        else:\n",
    "            s_rating.append(\"Neutral\")\n",
    "    return [s_score, s_rating]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement the Sentiment Analysis For Recalled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRecalled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put into function\n",
    "recalledSentValues = sentScore(newRecalled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign into new columns\n",
    "newRecalled['sentiment_score'] = recalledSentValues[0]\n",
    "newRecalled['sentiment'] = recalledSentValues[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the new dataframe with 2 new Sentimental Analysis columns for Recalled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRecalled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRecalled.recAgnPairId.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will run the Sentiment Analysis For Imagined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newImagined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run function and assign them into dataframe\n",
    "imaginedSentValues = sentScore(newImagined)\n",
    "newImagined['sentiment_score'] = imaginedSentValues[0]\n",
    "newImagined['sentiment'] = imaginedSentValues[1]\n",
    "\n",
    "#here are the 2 new Sentimental Analysis columns for Imagined\n",
    "newImagined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will run the Sentiment Analysis For Retold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRetold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply function and assign columns into dataframe\n",
    "retoldSentValues = sentScore(newRetold)\n",
    "newRetold['sentiment_score'] = retoldSentValues[0]\n",
    "newRetold['sentiment'] = retoldSentValues[1]\n",
    "\n",
    "#Here are the 2 new Sentimental Analysis columns for Retold\n",
    "newRetold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRetold.recAgnPairId.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spacy Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished the sentimental analysis, we will run the **Spacy Similarity** analysis. We are going to use their English large package for vectorization because all the stories that were told range drastically. By using the large package, we will be able to better vectorize our data with cosine similarity. Additionally, the retold group retells their story that they gave during their time in the recalled group given a summary that they created at the end of their recalled observation. So we are going to make a new dataset that only focuses on the subjects that were in the **recalled** and **retold** groups. This will allow for us to observe a change, if any, in their storytelling over a random time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedRecalledAndRetold.recAgnPairId.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy's en_core_web_lg\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run nlp function from earlier\n",
    "test1 = cleanedRecalledAndRetold['story'].iloc[0]\n",
    "test2 = cleanedRecalledAndRetold['retold stories'].iloc[0]\n",
    "doc1 = nlp(test1)\n",
    "doc2 = nlp(test2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the nlp function, we can see the similarity between doc1 and doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a function that compares the similarity between the recalled story and the retold story called **applyingSpacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyingSpacy(df):\n",
    "    sim_score = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        ogStory = df['story'].iloc[i]\n",
    "        newStory = df['retold stories'].iloc[i]\n",
    "        nlpComp1 = nlp(ogStory)\n",
    "        nlpComp2 = nlp(newStory)\n",
    "        sim_score.append(nlpComp1.similarity(nlpComp2))\n",
    "        \n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the function, this will take a minute to run\n",
    "sim_scores = applyingSpacy(cleanedRecalledAndRetold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets double check that all the stories were processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleanedRecalledAndRetold.shape)\n",
    "print(len(sim_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the stories were processed lets add it back into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedRecalledAndRetold['spacy_sim'] = sim_scores\n",
    "cleanedRecalledAndRetold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets read the age group to the dataframe so when we visualize we can see the differences in the age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageKey = cleanedRecalledAndRetold.apply(lambda row: ageGroup(row),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedRecalledAndRetold['AgeGroup'] = ageKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot our results from Spacy and see what we get\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedRecalledAndRetold.plot.scatter(x='time since recalled', y = 'spacy_sim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results seem to be fairly high so lets dive deeper in to why that might be\n",
    "- Spacy documentation states that when taking the similarity of a document it defaults to the average of the token vectors. An example they state is, “fast food” is the average of the vectors for “fast” and “food”, which isn’t necessarily representative of the phrase “fast food”\"\n",
    "- Therefore it could be that the words are similar but the idea is not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Analysis\n",
    "Let's dig a little deeper to try and see why these high overly high scores may be occuring. The first thing that comes to mind is if the stories are different lengths.\n",
    "We will create an example and see what the results are when the sentences are:\n",
    "- completely identical \n",
    "- identical but one has an extra sentence related to the previous \n",
    "- identical but one has an extra sentence not related to the previous \n",
    "- identical but with one having an extra sentence that is told in a different way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exact same sentences\n",
    "doc1 = nlp(\"I like burgers and dogs.\")\n",
    "doc2 = nlp('I like burgers and dogs.')\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compared to raw sentence comparison\n",
    "numberOfSimilarWords = 5\n",
    "totalWords = 5\n",
    "print(\"Raw comparison\", numberOfSimilarWords / totalWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same setences but one has an extra sentence that does relate to the previous\n",
    "doc1 = nlp(\"I like burgers and dogs. I also like pineapples\")\n",
    "doc2 = nlp('I like burgers and dogs.')\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compared to raw sentence comparison\n",
    "numberOfSimilarWords = 5\n",
    "totalWords = 9\n",
    "print(\"Raw comparison\", numberOfSimilarWords / totalWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same setences but one has an extra sentence that does not relate to the previous\n",
    "doc1 = nlp(\"I like burgers and dogs. Bob flies planes\")\n",
    "doc2 = nlp('I like burgers and dogs.')\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that sentences that are irrelevant decrease the score, and sentences that are similar decrease the score but not as much as an irrelevant extra sentence.\n",
    "But what about an extra sentence that basically says the same thing as the previous but in a different way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same setences but one has an extra sentence that repeats what is said but in a different way\n",
    "doc1 = nlp(\"I like burgers and dogs. Burgers and dogs are what I like\")\n",
    "doc2 = nlp('I like burgers and dogs.')\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the last sentence the similarity is the highest. With these examples we can more reasonably conclude that our results are in fact accurate for what we are trying to do. This is because we want to focus on how much the stories change, not necessarily if the stories are talking about the same thing. Something that could be interesting for the future is to look into how much the length of an overall document can affect these scores. But for the sake of this project we are going to assume that the results are accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing together the analysis from the Spacy package, let's compare the similarity score to the change in sentiment score. To do this, we are going to take the sentiment score from the recalled group and subtract it from the retold group by individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedAnalysis = cleanedRecalledAndRetold\n",
    "combinedAnalysis[\"sentChange\"] = np.nan\n",
    "combinedAnalysis = combinedAnalysis.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cRRKeys = cleanedRecalledAndRetold.recAgnPairId.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing these keys as the recAgnPairId does not exist in the newRecalled or the newRetold dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cRRKeys = np.delete(cRRKeys,95)\n",
    "cRRKeys = np.delete(cRRKeys,611)\n",
    "cRRKeys = np.delete(cRRKeys,797)\n",
    "cRRKeys = np.delete(cRRKeys,881)\n",
    "cRRKeys = np.delete(cRRKeys,939)\n",
    "cRRKeys = np.delete(cRRKeys,1032)\n",
    "cRRKeys = np.delete(cRRKeys,1068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberToPullVal = 0\n",
    "i=0\n",
    "for tagNumber in range(len(cRRKeys)):\n",
    "    #print(i)\n",
    "    #i +=1\n",
    "    recalledRow = newRecalled[newRecalled['recAgnPairId'] == cRRKeys[tagNumber]]\n",
    "    retoldRow = newRetold[newRetold['recAgnPairId'] == cRRKeys[tagNumber]]\n",
    "\n",
    "    #Pull the neg, neu, and pos from the column. Stored as a series and not a dict\n",
    "    #Putting it into a list then pulling from it\n",
    "    negArrReC = pd.DataFrame(recalledRow['sentiment_score'].tolist())['neg'].tolist()\n",
    "    neuArrReC = pd.DataFrame(recalledRow['sentiment_score'].tolist())['neu'].tolist()\n",
    "    posArrReC = pd.DataFrame(recalledRow['sentiment_score'].tolist())['pos'].tolist()\n",
    "\n",
    "    negArrReT = pd.DataFrame(retoldRow['sentiment_score'].tolist())['neg'].tolist()\n",
    "    neuArrReT = pd.DataFrame(retoldRow['sentiment_score'].tolist())['neu'].tolist()\n",
    "    posArrReT = pd.DataFrame(retoldRow['sentiment_score'].tolist())['pos'].tolist()\n",
    "\n",
    "    #Check the difference between values\n",
    "    newNegVal = negArrReT[numberToPullVal] - negArrReC[numberToPullVal] \n",
    "    newPoVal  = posArrReT[numberToPullVal] - posArrReC[numberToPullVal] \n",
    "\n",
    "    if(newPoVal > newNegVal):\n",
    "        combinedAnalysis.loc[combinedAnalysis.recAgnPairId == cRRKeys[tagNumber], 'sentChange'] = 'Pos'\n",
    "    elif(newPoVal < newNegVal):\n",
    "        combinedAnalysis.loc[combinedAnalysis.recAgnPairId == cRRKeys[tagNumber], 'sentChange'] = 'Neg'\n",
    "    else:\n",
    "        combinedAnalysis.loc[combinedAnalysis.recAgnPairId == cRRKeys[tagNumber], 'sentChange'] = 'Neu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedAnalysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedAnalysis.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the relationships between the columns **AgeGroup vs Draining**, **AgeGroup vs Stressful**, and **AgeGroup vs Importance** with the Retold and Recalled datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retold Agegroup vs stressful\n",
    "sns.violinplot(x='AgeGroup',data=newRetold,\n",
    "            y='stressful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retold Agegroup vs draining\n",
    "sns.violinplot(x='AgeGroup',data=newRetold,\n",
    "            y='draining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retold Agegroup vs importance\n",
    "sns.violinplot(x='AgeGroup',data=newRetold,\n",
    "            y='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recalled Agegroup vs stressful\n",
    "sns.violinplot(x='AgeGroup',data=newRecalled,\n",
    "            y='stressful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recalled Agegroup vs draining\n",
    "sns.violinplot(x='AgeGroup',data=newRecalled,\n",
    "            y='draining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recalled Agegroup vs importance\n",
    "sns.violinplot(x='AgeGroup',data=newRecalled,\n",
    "            y='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataframe's memType column\n",
    "combinedAnalysis['memType']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split our new dataset by age group for further analysis. We will discuss these plots and split datasets later in our conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the combined analysis dataset into youth, adult, and seniors only\n",
    "youthOnly = combinedAnalysis[combinedAnalysis['AgeGroup'] == 'Youth']\n",
    "adultOnly = combinedAnalysis[combinedAnalysis['AgeGroup'] == 'Adult']\n",
    "seniorOnly = combinedAnalysis[combinedAnalysis['AgeGroup'] == 'Senior']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IID. Data Visualizations for Sentimental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will look at visualizations for Recalled, Imagined and Retold by Sentiment and Age. In this section, we want to visualize the sentiment of each age group for Recalled, Imagined and Retold. The x-axis is the age while the y-axis is the percentage in their respective sentiment. Below each Bar Graph are the stats displaying each Age Group along with their exact percentage of positive and negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recalled Visualization\n",
    "\n",
    "# Create x-axis based on unique age values in the Data\n",
    "X = newRecalled['annotatorAge'].unique()\n",
    "X.sort()\n",
    "x_axis = np.arange(len(newRecalled['annotatorAge'].unique()))\n",
    "\n",
    "\n",
    "# Calculate Positive Amount and Percentages\n",
    "positive = []\n",
    "positive_total = 0\n",
    "for x in X:\n",
    "    value = len(newRecalled[(newRecalled['annotatorAge'] == x) & (newRecalled['sentiment'] == 'Positive')])\n",
    "    positive.append(value)\n",
    "    positive_total+=value\n",
    "\n",
    "positive_percentage = []\n",
    "for x in positive:\n",
    "    positive_percentage.append((x/positive_total) * 100)\n",
    "\n",
    "\n",
    "# Calculate Negative Amount and Percentages\n",
    "negative = []\n",
    "negative_total = 0\n",
    "for x in X:\n",
    "    value = len(newRecalled[(newRecalled['annotatorAge'] == x) & (newRecalled['sentiment'] == 'Negative')])\n",
    "    negative.append(value)\n",
    "    negative_total+=value\n",
    "\n",
    "negative_percentage = []\n",
    "for x in negative:\n",
    "    negative_percentage.append((x/negative_total) * 100)\n",
    "\n",
    "plt.xticks(x_axis, X)\n",
    "plt.bar(x_axis + 0.2 ,positive_percentage,0.4,label='Positive')\n",
    "plt.bar(x_axis - 0.2 ,negative_percentage,0.4,label='Negative')\n",
    "plt.ylabel('Percentage of Sentiment')\n",
    "plt.xlabel('Age')\n",
    "plt.title('Recalled Sentiment')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "positive_stats = {}\n",
    "negative_stats = {}\n",
    "index = 0\n",
    "for val in X:\n",
    "    positive_stats[val] = positive_percentage[index]\n",
    "    negative_stats[val] = negative_percentage[index]\n",
    "    index+=1\n",
    "print('---------- Positive Stats ----------')\n",
    "for i in positive_stats:\n",
    "    print(\"Age: {}\".format(i) + \" Percentage: {}\".format(positive_stats[i]))\n",
    "\n",
    "print('---------- Negative Stats ----------')\n",
    "for i in negative_stats:\n",
    "    print(\"Age: {}\".format(i) + \" Percentage: {}\".format(negative_stats[i]))\n",
    "\n",
    "#Imagined Visualization\n",
    "\n",
    "\n",
    "# Create x-axis based on unique age values in the Data\n",
    "X = newImagined['annotatorAge'].unique()\n",
    "X.sort()\n",
    "x_axis = np.arange(len(newImagined['annotatorAge'].unique()))\n",
    "\n",
    "\n",
    "# Calculate Positive Amount and Percentages\n",
    "positive = []\n",
    "positive_total = 0\n",
    "for x in X:\n",
    "    value = len(newImagined[(newImagined['annotatorAge'] == x) & (newImagined['sentiment'] == 'Positive')])\n",
    "    positive.append(value)\n",
    "    positive_total+=value\n",
    "\n",
    "positive_percentage = []\n",
    "for x in positive:\n",
    "    positive_percentage.append((x/positive_total) * 100)\n",
    "\n",
    "\n",
    "# Calculate Negative Amount and Percentages\n",
    "negative = []\n",
    "negative_total = 0\n",
    "for x in X:\n",
    "    value = len(newImagined[(newImagined['annotatorAge'] == x) & (newImagined['sentiment'] == 'Negative')])\n",
    "    negative.append(value)\n",
    "    negative_total+=value\n",
    "\n",
    "negative_percentage = []\n",
    "for x in negative:\n",
    "    negative_percentage.append((x/negative_total) * 100)\n",
    "\n",
    "plt.xticks(x_axis, X)\n",
    "plt.bar(x_axis + 0.2 ,positive_percentage,0.4,label='Positive')\n",
    "plt.bar(x_axis - 0.2 ,negative_percentage,0.4,label='Negative')\n",
    "plt.ylabel('Percentage of Sentiment')\n",
    "plt.xlabel('Age')\n",
    "plt.title('Imagined Sentiment')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "positive_stats = {}\n",
    "negative_stats = {}\n",
    "index = 0\n",
    "for val in X:\n",
    "    positive_stats[val] = positive_percentage[index]\n",
    "    negative_stats[val] = negative_percentage[index]\n",
    "    index+=1\n",
    "print('---------- Positive Stats ----------')\n",
    "for i in positive_stats:\n",
    "    print(\"Age: {}\".format(i) + \" Percentage: {}\".format(positive_stats[i]))\n",
    "\n",
    "print('---------- Negative Stats ----------')\n",
    "for i in negative_stats:\n",
    "    print(\"Age: {}\".format(i) + \" Percentage: {}\".format(negative_stats[i]))\n",
    "\n",
    "#Retold Visualization   \n",
    "\n",
    "\n",
    "# Create x-axis based on unique age values in the Data\n",
    "X = newRetold['annotatorAge'].unique()\n",
    "X.sort()\n",
    "x_axis = np.arange(len(newRetold['annotatorAge'].unique()))\n",
    "\n",
    "\n",
    "# Calculate Positive Amount and Percentages\n",
    "positive = []\n",
    "positive_total = 0\n",
    "for x in X:\n",
    "    value = len(newRetold[(newRetold['annotatorAge'] == x) & (newRetold['sentiment'] == 'Positive')])\n",
    "    positive.append(value)\n",
    "    positive_total+=value\n",
    "\n",
    "positive_percentage = []\n",
    "for x in positive:\n",
    "    positive_percentage.append((x/positive_total) * 100)\n",
    "\n",
    "\n",
    "# Calculate Negative Amount and Percentages\n",
    "negative = []\n",
    "negative_total = 0\n",
    "for x in X:\n",
    "    value = len(newRetold[(newRetold['annotatorAge'] == x) & (newRetold['sentiment'] == 'Negative')])\n",
    "    negative.append(value)\n",
    "    negative_total+=value\n",
    "\n",
    "negative_percentage = []\n",
    "for x in negative:\n",
    "    negative_percentage.append((x/negative_total) * 100)\n",
    "\n",
    "plt.xticks(x_axis, X)\n",
    "plt.bar(x_axis + 0.2 ,positive_percentage,0.4,label='Positive')\n",
    "plt.bar(x_axis - 0.2 ,negative_percentage,0.4,label='Negative')\n",
    "plt.ylabel('Percentage of Sentiment')\n",
    "plt.xlabel('Age')\n",
    "plt.title('Retold Sentiment')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "positive_stats = {}\n",
    "negative_stats = {}\n",
    "index = 0\n",
    "for val in X:\n",
    "    positive_stats[val] = positive_percentage[index]\n",
    "    negative_stats[val] = negative_percentage[index]\n",
    "    index+=1\n",
    "print('---------- Positive Stats ----------')\n",
    "for i in positive_stats:\n",
    "    print(\"Age: {}\".format(i) + \" Percentage: {}\".format(positive_stats[i]))\n",
    "\n",
    "print('---------- Negative Stats ----------')\n",
    "for i in negative_stats:\n",
    "    print(\"Age: {}\".format(i) + \" Percentage: {}\".format(negative_stats[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous graph showed us the relationships between Positve and Negative Sentiments by **Age**. We can see that the results between Sentiments by Age are pretty spread out and that there is no clear relationship between the 3 graphs. Though, if we look at each graph individually, we can see some trends throughout the different years. For example, for Recalled, there is a period of increased positivity between the ages 25 to 35. We can also see that for the Recalled and Retold graphs, between the ages of 45-55, there is mostly a negative sentiment within the groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will look at the relationship between Positive and Negative Sentiments by **AgeGroup**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot settings\n",
    "fig, axes = plt.subplots(3, 1,figsize=(10,15))\n",
    "fig.tight_layout(h_pad = 4.0)\n",
    "\n",
    "#Recalled Visualization\n",
    "graph_2 = sns.histplot(data = newRecalled, x=\"AgeGroup\", hue = 'sentiment', hue_order = ['Positive','Negative'],multiple='dodge', stat = 'percent',common_norm=False,ax=axes[0])\n",
    "for container in graph_2.containers:\n",
    "    graph_2.bar_label(container)\n",
    "\n",
    "graph_2.set(xlabel = 'Age Group')\n",
    "axes[0].set_title('Recalled Sentiment', fontsize=20)\n",
    "\n",
    "#Imagined Visualization\n",
    "graph_2 = sns.histplot(data = newImagined, x=\"AgeGroup\", hue = 'sentiment', hue_order = ['Positive','Negative'],multiple='dodge', stat = 'percent',common_norm=False,ax=axes[1])\n",
    "for container in graph_2.containers:\n",
    "    graph_2.bar_label(container)\n",
    "\n",
    "graph_2.set(xlabel = 'Age Group')\n",
    "axes[1].set_title('Imagined Sentiment', fontsize=20)\n",
    "\n",
    "#Retold Visualization\n",
    "graph_2 = sns.histplot(data = newRetold, x=\"AgeGroup\", hue = 'sentiment', hue_order = ['Positive','Negative'],multiple='dodge', stat = 'percent',common_norm=False,ax=axes[2])\n",
    "for container in graph_2.containers:\n",
    "    graph_2.bar_label(container)\n",
    "\n",
    "graph_2.set(xlabel = 'Age Group')\n",
    "axes[2].set_title('Retold Sentiment', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these graphs, the strongest relationship that stood out is how the Adult AgeGroup column seems to have a more Positive Sentiment than Negative relationship in all 3 Retold, Recalled, and Imagined Sentiments. Maybe this has something to do with the adult stage in life where people tend to be happier? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's visualize the Sentimental Analysis between **Retold vs. Recalled Stories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select positive and negative sentiments (remove neutral sentiment)\n",
    "posnegRetold = newRetold[(newRetold['sentiment'] == 'Positive') | (newRetold['sentiment'] == 'Negative')]\n",
    "posnegRecalled = newRecalled[(newRecalled['sentiment'] == 'Positive') | (newRecalled['sentiment'] == 'Negative')]\n",
    "\n",
    "#plot parameters\n",
    "x = posnegRetold['sentiment']\n",
    "y = posnegRecalled['sentiment']\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "values, bins, patches = plt.hist([x, y], bins=np.arange(3)-0.5, label=['Retold Stories', 'Recalled Stories'],density=True)\n",
    " \n",
    "plt.legend(loc='upper right')\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "for container in ax.containers:\n",
    "    labels = [f'{x:.1%}' for x in container.datavalues]\n",
    "    ax.bar_label(container, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph, we can see that when comparing Positive and Negative sentiments between Retold and Recalled stories, there are more Positive Retold stories than Recalled stories. Also, there are more Negative stories in Recalled than Retold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for consistency, we will add the plots that we've seen and analyzed from the Spacy Similarity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedRecalledAndRetold.plot.scatter(x='time since recalled', y = 'spacy_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cleanedRecalledAndRetold[cleanedRecalledAndRetold['time since recalled'] < 250]\n",
    "test.plot.scatter(x='time since recalled', y = 'spacy_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ages = ['Youth','Adult','Senior']\n",
    "sns.relplot(data=combinedAnalysis, x='time since recalled', y='spacy_sim', hue='AgeGroup', hue_order=_ages, aspect=1.61)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Conclusion and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above we want to see how emotion affects memory so let's look into the results we got. First lets see if the emotion of our age group has increased or decreased over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='AgeGroup',hue='sentChange',data=combinedAnalysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the emotion change was actually more positive over time in the Adult and Senior age group. As for the youth group the negative and positive emotion is about the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the spacy distribution classified by age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youth = sns.displot(youthOnly, x='spacy_sim',bins=15)\n",
    "youth.set(title='Youth Spacy Distribution')\n",
    "adult = sns.displot(adultOnly, x='spacy_sim',bins=15,color='orange')\n",
    "adult.set(title='Adult Spacy Distribution')\n",
    "senior = sns.displot(seniorOnly, x='spacy_sim',bins=15)\n",
    "senior.set(title='Senior Spacy Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, looking at the distributions, the Adult distribution appears to show the overall best retelling of the previous story, then the Youth distribution, and finally the Senior distribution. This shows us that even if there is better emotion, it does not necessarily lead to better memory. If emotion were to help memory we would see the Senior distribution being the best followed by Adult and then finally Youth.\n",
    "\n",
    "Let's look at the emotion variables that might be driving this increase. We decided that the variables that speak the most about emotion are:\n",
    "- Draining which describes how emotionally drained the individual was when telling the story\n",
    "- Importance which describes how driven the individual was when telling the story\n",
    "- Stressful which describes how stressed the individual was when telling the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRecalled.groupby('AgeGroup').mean().drop(columns=['annotatorAge','frequency','logTimeSinceEvent',\n",
    "                                                   'similarity','timeSinceEvent','distracted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRetold.groupby('AgeGroup').mean().drop(columns=['annotatorAge','frequency','logTimeSinceEvent',\n",
    "                                                   'similarity','timeSinceEvent','distracted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three emotional variables are done on a Likert scale meaning 5 being the most stress, 3 being a neutral amount of stress and 1 being no stress at all. Between the two plots, we can see that individuals on average were less emotionally drained during the retelling of the story as opposed to recalling it. The average importance level was higher for each age group during the recalling of the story versus the retelling of the story where they were lower. Finally, the stress decreased for each age group when they were retelling the story as opposed to recalling it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at violin plots to help us better see the distribution of the emotions by age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stressRec = sns.violinplot(x='AgeGroup',data=newRecalled,\n",
    "            y='stressful')\n",
    "stressRec.set(title='Recalled Stress Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stressRet = sns.violinplot(x='AgeGroup',data=newRetold,\n",
    "            y='stressful')\n",
    "stressRet.set(title='Retold Stress Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the stress distribution thinned out at 6 and increase from 2 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importanceRec = sns.violinplot(x='AgeGroup',data=newRecalled,\n",
    "            y='importance')\n",
    "importanceRec.set(title='Recalled Importance Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importanceRet = sns.violinplot(x='AgeGroup',data=newRetold,\n",
    "            y='importance')\n",
    "importanceRet.set(title='Retold Importance Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the importance distribution filled in the thinner spots and grew more from 4 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drainingRec = sns.violinplot(x='AgeGroup',data=newRecalled,\n",
    "            y='draining')\n",
    "drainingRec.set(title='Recalled Draining Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drainingRet = sns.violinplot(x='AgeGroup',data=newRetold,\n",
    "            y='draining')\n",
    "drainingRet.set(title='Retold Draining Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that draining followed a similar pattern as stressed did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall\n",
    "We can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion\n",
    "#Discussion of your results and how they address your experimental question\n",
    "#Limitations of analysis discussed\n",
    "#What additional experiments would be interesting, and what data would you need?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
